{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with TensorFlow - II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Notes compiled from Chapter 9: Hands-On Machine Learning with Scikit-Learn and TensorFlow_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Gradient Descent - Manual Computation vs Autodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the California Housing Dataset as an example in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data_plus_bias = scaler.fit_transform(housing_data_plus_bias)\n",
    "\n",
    "n_epoochs = 1500\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  **Manually Computing the Gradients:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For linear regression:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Square error vector = $(X \\theta - y)^2$, where element wise square of error is computed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Square Error = MSE(X, $h_\\theta$) = $\\frac{1}{m}$ $\\sum_{i=1}^{m} (X^{(i)}\\theta - y^{(i)})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim($\\theta$) = (n+1) x 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim(X) = m x (n+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where m = size of training set, and n = input feature size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$i^{th}$ row of X contains the n feature values for training set datapoint $X^i$, and $X^i_0=1$ $\\forall i$; $\\space$ where $X^i_j$ means the $i^{th}$ row and $j^{th}$ column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient vector = $\\frac{\\partial \\text{MSE(X,}\\space h_{\\theta})}{\\partial \\theta_j}$, for j in range(1, (n+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE(X, $h_\\theta$) = $\\frac{1}{m}$ $\\sum_{i=1}^{m} (X^{(i)}\\theta - y^{(i)})^{2}$ = $\\frac{1}{m}$ $\\sum_{i=1}^{m}$ $( (\\theta_{0} + \\theta _{1} X^{i}_{1} + .. + \\theta _{n} X^{i}_{n}) - y^{(i)})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above equation, calculating partial derivatives: $\\frac{\\partial \\text{MSE(X,}\\space h_{\\theta})}{\\partial \\theta_k}$ = $\\frac{2}{m}$ $\\sum_{i=1}^{m} X^{i}_{k} \\space E_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient vector (=Transpose of the partial derivate vector) of the Mean Square Error function = $\\frac{2}{m}$ $X^{T}$ (X $\\theta$ - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0   MSE=  8.083024\n",
      "Epoch:  100   MSE=  5.122897\n",
      "Epoch:  200   MSE=  5.0061646\n",
      "Epoch:  300   MSE=  4.949822\n",
      "Epoch:  400   MSE=  4.910001\n",
      "Epoch:  500   MSE=  4.881157\n",
      "Epoch:  600   MSE=  4.860204\n",
      "Epoch:  700   MSE=  4.8449645\n",
      "Epoch:  800   MSE=  4.833867\n",
      "Epoch:  900   MSE=  4.825774\n",
      "Epoch:  1000   MSE=  4.8198633\n",
      "Epoch:  1100   MSE=  4.815539\n",
      "Epoch:  1200   MSE=  4.812369\n",
      "Epoch:  1300   MSE=  4.8100395\n",
      "Epoch:  1400   MSE=  4.808325\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Creating the computational graph\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "manual_gradients = (2/m)*tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * manual_gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Executing the operations in the graph\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epoochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch: \", epoch, \"  MSE= \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "\n",
    "    opt_theta = theta.eval()\n",
    "    # print(opt_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  **Using Autodiff for Computing the Gradients:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow uses reverse-mode autodiff that takes ($n_outputs$ + 1) number of graph traversals to compute all gradients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _gradients()_ function takes an op (for eg: mse) and a list of variables (for eg: theta), and creates a list of ops (one per variable) to compute the gradients of the op with regard to each variable. In the below snippet, the autodiff_gradients node computes the gradient vector of the MSE with regard to theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0   MSE=  10.54808\n",
      "Epoch:  100   MSE=  4.9338737\n",
      "Epoch:  200   MSE=  4.871462\n",
      "Epoch:  300   MSE=  4.85152\n",
      "Epoch:  400   MSE=  4.8384757\n",
      "Epoch:  500   MSE=  4.8290787\n",
      "Epoch:  600   MSE=  4.822237\n",
      "Epoch:  700   MSE=  4.8172426\n",
      "Epoch:  800   MSE=  4.8135915\n",
      "Epoch:  900   MSE=  4.8109164\n",
      "Epoch:  1000   MSE=  4.808952\n",
      "Epoch:  1100   MSE=  4.807507\n",
      "Epoch:  1200   MSE=  4.806441\n",
      "Epoch:  1300   MSE=  4.805652\n",
      "Epoch:  1400   MSE=  4.805066\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Creating the computational graph\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "autodiff_gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * autodiff_gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Executing the operations in the graph\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epoochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch: \", epoch, \"  MSE= \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "\n",
    "    opt_theta = theta.eval()\n",
    "    # print(opt_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the graph using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0   MSE=  8.291836\n",
      "Epoch:  100   MSE=  5.0304093\n",
      "Epoch:  200   MSE=  4.9413304\n",
      "Epoch:  300   MSE=  4.904329\n",
      "Epoch:  400   MSE=  4.877926\n",
      "Epoch:  500   MSE=  4.8586082\n",
      "Epoch:  600   MSE=  4.844426\n",
      "Epoch:  700   MSE=  4.833989\n",
      "Epoch:  800   MSE=  4.8262877\n",
      "Epoch:  900   MSE=  4.8205886\n",
      "Epoch:  1000   MSE=  4.8163576\n",
      "Epoch:  1100   MSE=  4.8132057\n",
      "Epoch:  1200   MSE=  4.8108487\n",
      "Epoch:  1300   MSE=  4.809079\n",
      "Epoch:  1400   MSE=  4.807745\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# Creating the computational graph\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "autodiff_gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * autodiff_gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "# Executing the operations in the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epoochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch: \", epoch, \"  MSE= \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "\n",
    "    opt_theta = theta.eval()\n",
    "\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](TensorboardGraphVis.png \"Title\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
