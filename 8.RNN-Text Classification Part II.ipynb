{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8.RNN-Text Classification Part II.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KiGvZ9VzA-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade grpcio\n",
        "!pip install tensorflow==2.0\n",
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuAY8j58zEzc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "5dadc6e6-6e2c-4726-f774-a5e51abefd88"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.config.experimental.list_physical_devices())\n",
        "print(tf.test.is_gpu_available())\n",
        "print(tf.test.is_built_with_cuda())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n",
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpuA8y0UzKEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9p0ds9YJ5Jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h8tqo9iziuX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7608e6d-3962-4643-e383-e5e857c06fd6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "data_dir_path = 'gdrive/My Drive/tensorflow_datasets/'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-L0sjGzzrjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_validation_split = tfds.Split.TRAIN.subsplit([9, 1])\n",
        "((train_dataset, validation_dataset), test_dataset), info = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True, data_dir=data_dir_path, download=False, split=(train_validation_split, tfds.Split.TEST))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AtD0fkezys5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "96597a19-78fc-4612-b106-505eae2ea4b2"
      },
      "source": [
        "print(\"info features: \", info.features)\n",
        "encoder = info.features[\"text\"].encoder\n",
        "print(\"\\n Vocabulary size: \", encoder.vocab_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "info features:  FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
            "})\n",
            "\n",
            " Vocabulary size:  8185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_EIgZl7z81j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# fills a buffer with buffer_size elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required.\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "# output_shapes returns the shape of each component of an element of this dataset.\n",
        "train_dataset = train_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(train_dataset))\n",
        "\n",
        "validation_dataset = validation_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(validation_dataset))\n",
        "\n",
        "test_dataset = test_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(test_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkvQyeeI3d_9",
        "colab_type": "text"
      },
      "source": [
        "The base class [RNN](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN?version=stable) for recurrent layers inherits from class keras.layers.Layer. Each RNN cell isntance must have the following:\n",
        "\n",
        "*   state_size attribute\n",
        "*   output_size attriute\n",
        "*   call(input_at_t, state_at_t) method, which return output_at_t and state_at_t_plus_1.\n",
        "*   get_initial_state(inputs=None, batch_size=None, dtype=None) method that creates a tensor meant to be fed to call() as the initial state, if the user didn't specify any initial state via other means.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFDUmUUJ2Di-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomRNNCell(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, **kwargs):\n",
        "        self.units = units\n",
        "        self.state_size = units\n",
        "        super(CustomRNNCell, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # add_weight is from base_layer class, used to add a new variable to the layer\n",
        "        \n",
        "        # kernel initializer, weight matrix used for the linear transformation of the inputs\n",
        "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units), initializer='uniform', name='kernel')\n",
        "\n",
        "        # recurrent initializer, weight matrix used for the linear transformation of the recurrent state.\n",
        "        self.recurrent_kernel = self.add_weight(shape=(self.units, self.units), initializer='uniform', name='recurrent_kernel')\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        prev_output = states[0]\n",
        "        h = K.dot(inputs, self.kernel)\n",
        "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
        "        # For a simple RNN, the output_at_t and hidden_state_at_t_plus_1 is same.\n",
        "        return output, [output]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LzzzLfp5Pua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "cf8083d4-faf9-4b67-eaed-acadbc2f5f4a"
      },
      "source": [
        "use_dropout = False\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Embedding(input_dim=encoder.vocab_size, output_dim=64))\n",
        "model.add(tf.keras.layers.RNN([CustomRNNCell(8)]))\n",
        "if use_dropout:\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          523840    \n",
            "_________________________________________________________________\n",
            "rnn (RNN)                    (None, 8)                 576       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                144       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 524,577\n",
            "Trainable params: 524,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgVflgpZ5cGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_crossentropy(y_true, y_pred, from_logits=False):\n",
        "    y_true = tf.cast(y_true, y_pred.dtype)\n",
        "    def get_epsilon():\n",
        "        # epsilon_value = 1e-7\n",
        "        return tf.keras.backend.epsilon()\n",
        "    \n",
        "    if not from_logits:\n",
        "#             if y_pred.op.type == \"Sigmoid\":\n",
        "#                 TODO: dont clip. Use the from_logits directly.\n",
        "        epsilon = get_epsilon()\n",
        "        clipped_y_pred = tf.clip_by_value(y_pred, clip_value_min=epsilon, clip_value_max=(1.-epsilon))\n",
        "        bce = tf.math.multiply(y_true, tf.math.log(tf.math.add(clipped_y_pred, epsilon)))\n",
        "        temp = tf.math.multiply(tf.math.subtract(1., y_true), tf.math.log(tf.math.add(epsilon, tf.math.subtract(1., clipped_y_pred))))\n",
        "        return tf.math.negative(tf.reduce_mean(tf.math.add(bce, temp)))\n",
        "    else:\n",
        "        # - x * z + log(1 + exp(x)), x = logits, z = labels\n",
        "        return tf.reduce_mean(tf.math.add(tf.math.negative(tf.math.multiply(y_pred, y_true)), tf.math.log(tf.math.add(1., tf.math.exp(y_pred)))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYhWpg6MMW30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=binary_crossentropy, optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NljsziftNeRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [\n",
        "  # Write TensorBoard logs to `./tf_logs/rnn` directory\n",
        "  tf.keras.callbacks.TensorBoard(log_dir='gdrive/My Drive/Colab Notebooks/DLCodeSnippets/tf_logs/rnn_1', histogram_freq=5, write_images=True, write_graph=True),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1RuTehe7MjX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d45b1bc6-535b-4c95-d1f6-302b94737728"
      },
      "source": [
        "history = model.fit(train_dataset, epochs=10, validation_data=validation_dataset, validation_steps=5, callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "      1/Unknown - 4s 4s/step - loss: 0.6932 - accuracy: 0.4375WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.823969). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.823969). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "352/352 [==============================] - 400s 1s/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "352/352 [==============================] - 408s 1s/step - loss: 0.6931 - accuracy: 0.4971 - val_loss: 0.6923 - val_accuracy: 0.5094\n",
            "Epoch 3/10\n",
            "352/352 [==============================] - 409s 1s/step - loss: 0.6931 - accuracy: 0.4918 - val_loss: 0.6926 - val_accuracy: 0.4969\n",
            "Epoch 4/10\n",
            "196/352 [===============>..............] - ETA: 3:02 - loss: 0.6925 - accuracy: 0.5016"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg-SzZWkAHKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}