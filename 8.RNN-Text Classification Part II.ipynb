{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "yuAY8j58zEzc",
    "outputId": "5dadc6e6-6e2c-4726-f774-a5e51abefd88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU')\n",
      "PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')\n",
      "PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices()\n",
    "print(*physical_devices, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the second GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_var = tf.constant([1.0,2.0,3.0], name='test_var')\n",
    "# print(test_var)\n",
    "# print(\"Variable placed on device: \", test_var.device)\n",
    "\n",
    "# # with tf.device('/device:XLA_GPU:1'):\n",
    "# a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='a')\n",
    "# b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "# print(a.device)\n",
    "# print(b.device)\n",
    "\n",
    "# ?????\n",
    "# print(\"Is GPU available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpuA8y0UzKEL"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from time import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u9p0ds9YJ5Jk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import version;\n",
    "print(version.VERSION)\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3h8tqo9iziuX",
    "outputId": "d7608e6d-3962-4643-e383-e5e857c06fd6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "data_dir_path = './datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1-L0sjGzzrjf"
   },
   "outputs": [],
   "source": [
    "train_validation_split = tfds.Split.TRAIN.subsplit([6, 4])\n",
    "((train_dataset, validation_dataset), test_dataset), info = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True, data_dir=data_dir_path, download=False, split=(train_validation_split, tfds.Split.TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "2AtD0fkezys5",
    "outputId": "96597a19-78fc-4612-b106-505eae2ea4b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info features:  FeaturesDict({\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
      "    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
      "})\n",
      "\n",
      " Vocabulary size:  8185\n"
     ]
    }
   ],
   "source": [
    "print(\"info features: \", info.features)\n",
    "encoder = info.features[\"text\"].encoder\n",
    "print(\"\\n Vocabulary size: \", encoder.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_EIgZl7z81j"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# fills a buffer with buffer_size elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required.\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "# output_shapes returns the shape of each component of an element of this dataset.\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(train_dataset))\n",
    "\n",
    "validation_dataset = validation_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(validation_dataset))\n",
    "\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkvQyeeI3d_9"
   },
   "source": [
    "The base class [RNN](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN?version=stable) for recurrent layers inherits from class keras.layers.Layer. Each RNN cell isntance must have the following:\n",
    "\n",
    "*   state_size attribute\n",
    "*   output_size attriute\n",
    "*   call(input_at_t, state_at_t) method, which return output_at_t and state_at_t_plus_1.\n",
    "*   get_initial_state(inputs=None, batch_size=None, dtype=None) method that creates a tensor meant to be fed to call() as the initial state, if the user didn't specify any initial state via other means.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFDUmUUJ2Di-"
   },
   "outputs": [],
   "source": [
    "class CustomRNNCell(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        \n",
    "        if 'teacher_forcing' in kwargs:\n",
    "            setattr(self, 'teacher_forcing', kwargs['teacher_forcing'])\n",
    "        else:\n",
    "            setattr(self, 'teacher_forcing', False)\n",
    "        \n",
    "        setattr(self, 'teacher_forcing_ratio', 0.4)\n",
    "        \n",
    "        super(CustomRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # add_weight is from base_layer class, used to add a new variable to the layer\n",
    "        \n",
    "        # kernel initializer, weight matrix used for the linear transformation of the inputs\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units), initializer='uniform', \n",
    "                                      name='kernel')\n",
    "\n",
    "        # recurrent initializer, weight matrix used for the linear transformation of the recurrent state.\n",
    "        self.recurrent_kernel = self.add_weight(shape=(self.units, self.units), initializer='glorot_uniform', \n",
    "                                                name='recurrent_kernel')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        #if self.teacher_forcing:\n",
    "            #force = True if random.random() < self.teacher_forcing_ratio else False\n",
    "            #if force:\n",
    "            # TODO: \n",
    "        prev_output = states[0]\n",
    "        h = K.dot(inputs, self.kernel)\n",
    "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
    "        # For a simple RNN, the output_at_t and hidden_state_at_t_plus_1 is same.\n",
    "        return output, [output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction:\n",
    "    @staticmethod\n",
    "    def binary_crossentropy(y_true, y_pred, from_logits=False):\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        def get_epsilon():\n",
    "            # epsilon_value = 1e-7\n",
    "            return tf.keras.backend.epsilon()\n",
    "\n",
    "        if not from_logits:\n",
    "            if y_pred.op.type == \"Sigmoid\":\n",
    "                tf.reduce_mean(tf.math.add(tf.math.negative(tf.math.multiply(y_pred, y_true)), \n",
    "                                           tf.math.log(tf.math.add(1., tf.math.exp(y_pred)))))\n",
    "            epsilon = get_epsilon()\n",
    "            clipped_y_pred = tf.clip_by_value(y_pred, clip_value_min=epsilon, clip_value_max=(1.-epsilon))\n",
    "            bce = tf.math.multiply(y_true, tf.math.log(tf.math.add(clipped_y_pred, epsilon)))\n",
    "            temp = tf.math.multiply(tf.math.subtract(1., y_true), \n",
    "                                    tf.math.log(tf.math.add(epsilon, tf.math.subtract(1., clipped_y_pred))))\n",
    "            return tf.math.negative(tf.reduce_mean(tf.math.add(bce, temp)))\n",
    "        else:\n",
    "            # - x * z + log(1 + exp(x)), x = logits, z = labels\n",
    "            return tf.reduce_mean(tf.math.add(tf.math.negative(tf.math.multiply(y_pred, y_true)), \n",
    "                                              tf.math.log(tf.math.add(1., tf.math.exp(y_pred)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "7LzzzLfp5Pua",
    "outputId": "cf8083d4-faf9-4b67-eaed-acadbc2f5f4a"
   },
   "outputs": [],
   "source": [
    "def generate_model(use_dropout=False):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=encoder.vocab_size, output_dim=64))\n",
    "    model.add(tf.keras.layers.RNN([CustomRNNCell(8)]))\n",
    "    if use_dropout:\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(loss=LossFunction.binary_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_dataset, validation_dataset, epochs=20):\n",
    "#     callbacks = [\n",
    "#         # Write TensorBoard logs to `./tf_logs/rnn` directory\n",
    "#         tf.keras.callbacks.TensorBoard(log_dir='./tf_logs/rnn_1', histogram_freq=10, write_graph=True)\n",
    "#     ]\n",
    "    callbacks = []\n",
    "    \n",
    "    history = model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset, validation_steps=5,\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ./tf_logs/rnn_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Gg-SzZWkAHKc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 8)                 576       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 524,577\n",
      "Trainable params: 524,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = generate_model()\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 422s 1s/step - loss: 0.6932 - accuracy: 0.4963 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "352/352 [==============================] - 342s 973ms/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.4969\n",
      "Epoch 3/20\n",
      "352/352 [==============================] - 341s 970ms/step - loss: 0.6929 - accuracy: 0.5016 - val_loss: 0.6920 - val_accuracy: 0.5125\n",
      "Epoch 4/20\n",
      "352/352 [==============================] - 337s 958ms/step - loss: 0.6893 - accuracy: 0.5025 - val_loss: 0.6968 - val_accuracy: 0.5094\n",
      "Epoch 5/20\n",
      "352/352 [==============================] - 335s 952ms/step - loss: 0.6852 - accuracy: 0.5049 - val_loss: 0.6915 - val_accuracy: 0.4969\n",
      "Epoch 6/20\n",
      "352/352 [==============================] - 346s 982ms/step - loss: 0.6831 - accuracy: 0.5053 - val_loss: 0.6954 - val_accuracy: 0.5125\n",
      "Epoch 7/20\n",
      "352/352 [==============================] - 344s 978ms/step - loss: 0.6820 - accuracy: 0.5041 - val_loss: 0.6984 - val_accuracy: 0.4969\n",
      "Epoch 8/20\n",
      "352/352 [==============================] - 336s 954ms/step - loss: 0.6829 - accuracy: 0.5050 - val_loss: 0.7095 - val_accuracy: 0.5094\n",
      "Epoch 9/20\n",
      "352/352 [==============================] - 341s 969ms/step - loss: 0.6828 - accuracy: 0.5034 - val_loss: 0.7028 - val_accuracy: 0.4969\n",
      "Epoch 10/20\n",
      "352/352 [==============================] - 344s 977ms/step - loss: 0.6822 - accuracy: 0.5051 - val_loss: 0.7039 - val_accuracy: 0.4969\n",
      "Epoch 11/20\n",
      "352/352 [==============================] - 344s 976ms/step - loss: 0.6820 - accuracy: 0.5035 - val_loss: 0.7079 - val_accuracy: 0.4938\n",
      "Epoch 12/20\n",
      "352/352 [==============================] - 344s 977ms/step - loss: 0.6820 - accuracy: 0.5066 - val_loss: 0.7075 - val_accuracy: 0.4938\n",
      "Epoch 13/20\n",
      "352/352 [==============================] - 344s 977ms/step - loss: 0.6809 - accuracy: 0.5077 - val_loss: 0.7135 - val_accuracy: 0.4938\n",
      "Epoch 14/20\n",
      "352/352 [==============================] - 341s 970ms/step - loss: 0.6817 - accuracy: 0.5062 - val_loss: 0.7181 - val_accuracy: 0.5094\n",
      "Epoch 15/20\n",
      "352/352 [==============================] - 341s 970ms/step - loss: 0.6821 - accuracy: 0.5061 - val_loss: 0.7170 - val_accuracy: 0.4938\n",
      "Epoch 16/20\n",
      "352/352 [==============================] - 343s 974ms/step - loss: 0.6814 - accuracy: 0.5068 - val_loss: 0.7294 - val_accuracy: 0.5094\n",
      "Epoch 17/20\n",
      "352/352 [==============================] - 339s 963ms/step - loss: 0.6811 - accuracy: 0.5053 - val_loss: 0.7443 - val_accuracy: 0.4938\n",
      "Epoch 18/20\n",
      "352/352 [==============================] - 346s 984ms/step - loss: 0.6822 - accuracy: 0.5071 - val_loss: 0.7356 - val_accuracy: 0.4938\n",
      "Epoch 19/20\n",
      "352/352 [==============================] - 342s 972ms/step - loss: 0.6818 - accuracy: 0.5092 - val_loss: 0.7368 - val_accuracy: 0.5094\n",
      "Epoch 20/20\n",
      "352/352 [==============================] - 342s 971ms/step - loss: 0.6815 - accuracy: 0.5092 - val_loss: 0.7296 - val_accuracy: 0.4938\n",
      "CPU times: user 4h 44min 43s, sys: 31min 10s, total: 5h 15min 54s\n",
      "Wall time: 1h 55min 16s\n"
     ]
    }
   ],
   "source": [
    "%time train_model(model, train_dataset, validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    391/Unknown - 128s 328ms/step - loss: 0.7559 - accuracy: 0.5006"
     ]
    }
   ],
   "source": [
    "rnn_test_loss, rnn_test_acc = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rnn_classification', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn_1 (RNN)                  (None, 8)                 576       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 524,577\n",
      "Trainable params: 524,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "new_model = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = compile_model(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6932723, 0.40625]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_dataset.__iter__().next()\n",
    "\n",
    "# This initializes the variables used by the optimizers, as well as any stateful metric variables\n",
    "# The optimizer state is preserved as well, so we can resume training where we left off\n",
    "new_model.train_on_batch(p[0], p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f935de62e80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the state of the old model\n",
    "new_model.load_weights('rnn_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the model state has been preserved\n",
    "old_predictions = model.predict(test_dataset)\n",
    "new_predictions = new_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(old_predictions, new_predictions, rtol=1e-6, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using hyperparam tuning and regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dropout, dense layer size, 2 custom recurrent layers with teacher forcing, early stopping after 4 epochs and regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# Clear logs from previous runs \n",
    "# rm -rf ./tf_logs/rnn_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reg:\n",
    "    @staticmethod\n",
    "    def l1_reg(weight_matrix):\n",
    "        return 0.01 * K.sum(K.abs(weight_matrix))\n",
    "    \n",
    "    @staticmethod\n",
    "    def l2_reg(weight_matrix):\n",
    "        return 0.01 * 0.5 * K.sum(K.square(weight_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "gradient_mean = {}\n",
    "\n",
    "class GradHistory(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "      with tf.GradientTape() as tape:\n",
    "        loss = self.model(self.model.trainable_weights)\n",
    "        x = tape.gradient(loss, self.model.trainable_weights)\n",
    "        # pdb.set_trace()\n",
    "        for i in range(0, len(x)):\n",
    "            if i in gradient_mean:\n",
    "                gradient_mean[i].append(tf.reduce_mean(x[i]))\n",
    "            else:\n",
    "                gradient_mean[i] = [tf.reduce_mean(x[i])]\n",
    "\n",
    "gradient_cb = GradHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerRNN:\n",
    "    \n",
    "    def __init__(self, teacher_forcing=False):\n",
    "        # number of units in 1st and 2nd recurrent layer, and the next dense layer\n",
    "        self.num_units_l1 = hp.HParam('num_units_l1', hp.Discrete([8, 16, 32, 64]))\n",
    "        self.num_units_l2 = hp.HParam('num_units_l2', hp.Discrete([8, 16, 32, 64]))\n",
    "        self.num_units_l3 = hp.HParam('num_units_l3', hp.Discrete([10, 25, 40]))\n",
    "        self.dropout = hp.HParam('dropout', hp.Discrete([0.3, 0.4]))\n",
    "                \n",
    "        # self.learning_rate = hp.HParam('learning_rate', hp.RealInterval(0.01, 0.5))\n",
    "        # sgd = tf.optimizers.SGD(clipvalue=5.0, name='sgd')\n",
    "        # self.optimizer = sgd\n",
    "        self.optimizer = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "        \n",
    "        self.hparams = {self.optimizer: self.optimizer, self.num_units_l1: self.num_units_l1, \n",
    "                        self.num_units_l2: self.num_units_l2, self.num_units_l3: self.num_units_l3, \n",
    "                        self.dropout: self.dropout}\n",
    "        \n",
    "        self.teacher_forcing = teacher_forcing\n",
    "        \n",
    "        self.model = None\n",
    "        \n",
    "        METRIC_ACCURACY = 'accuracy'\n",
    "        \n",
    "        self.init_timestamp = int(time())\n",
    "        \n",
    "        print(\"MODEL INIT TIMESTAMP: \", str(self.init_timestamp))\n",
    "        \n",
    "        self.log_dir = \"./tf_logs/rnn_classification_\" + str(self.init_timestamp) +\"/\"\n",
    "        with tf.summary.create_file_writer(self.log_dir).as_default():\n",
    "            hp.hparams_config(hparams=[self.optimizer, self.num_units_l1, self.num_units_l2, \n",
    "                                       self.num_units_l3, self.dropout], \n",
    "                              metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def loss_function(self, y_true, y_pred):\n",
    "        r = 0.0\n",
    "        for w in self.model.trainable_weights:\n",
    "            r += Reg.l2_reg(w)\n",
    "        l = LossFunction.binary_crossentropy(y_true, y_pred) + r\n",
    "        return l\n",
    "    \n",
    "#     def loss_function(self, y_true, y_pred):\n",
    "#         return tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    def generate_model(self, params):\n",
    "        \n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(tf.keras.layers.Embedding(input_dim=encoder.vocab_size, output_dim=64))\n",
    "        self.model.add(tf.keras.layers.RNN([CustomRNNCell(params[self.num_units_l1]), \n",
    "                                            CustomRNNCell(params[self.num_units_l2])]))\n",
    "        self.model.add(tf.keras.layers.Dropout(params[self.dropout]))\n",
    "        self.model.add(tf.keras.layers.Dense(params[self.num_units_l3], activation='relu'))\n",
    "        self.model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        print(self.model.summary())\n",
    "        return self.model\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def save_model(self):\n",
    "        cp = time()\n",
    "        model.save_weights(self.logdir + '/saved_models/model_' + cp, save_format='tf')\n",
    "        return\n",
    "    \n",
    "    def compile_model(self, loss_function, optimizer):\n",
    "        self.model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "        return self.model\n",
    "    \n",
    "    def train_model(self, hparams, train_data, cross_validation_data, run_index):\n",
    "        self.generate_model(hparams)\n",
    "        self.compile_model(self.loss_function, hparams[self.optimizer])\n",
    "        #self.compile_model(self.loss_function, self.optimizer)\n",
    "        \n",
    "        callbacks = [\n",
    "            # Early stopping\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4),\n",
    "            # logging train and validation accuracy each epoch\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=self.log_dir + run_index),\n",
    "            # gradient sum callback\n",
    "            gradient_cb,\n",
    "            # checkpoint\n",
    "            #tf.keras.callbacks.ModelCheckpoint(filepath=, save_weights_only=True, save_best_only=True)\n",
    "        ]\n",
    "        \n",
    "        self.model.fit(train_data, epochs=10, validation_data=cross_validation_data, callbacks=callbacks, \n",
    "                       verbose=1)\n",
    "        _, accuracy = self.model.evaluate(cross_validation_data)\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def run(self, run_dir, hparams, train_data, cross_validation_data):\n",
    "        K.clear_session()\n",
    "        run_index = run_dir.split(\"-\")[1]\n",
    "        with tf.summary.create_file_writer(run_dir).as_default():\n",
    "            # record the values used in this trial\n",
    "            hp.hparams(hparams)\n",
    "            acc = self.train_model(hparams, train_dataset, validation_dataset, run_index)\n",
    "            tf.summary.scalar('accuracy', acc, step=int(run_index))\n",
    "        return acc\n",
    "    \n",
    "    def random_search(self, train, cross_val, seed):\n",
    "        rng = random.Random(seed)\n",
    "        total_points_explored = 1\n",
    "        \n",
    "        acc_params = []\n",
    "        \n",
    "        for session_index in range(total_points_explored):\n",
    "            hparams = {h: h.domain.sample_uniform(rng) for h in self.hparams}\n",
    "            run_name = \"run-%d\" % session_index\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            acc = self.run(self.log_dir + \"tune/\" + run_name, hparams, train, cross_val)\n",
    "            session_index += 1\n",
    "            acc_params.append((acc, hparams))\n",
    "        \n",
    "        return total_points_explored, acc_params\n",
    "    \n",
    "    def setup_model(self, params):\n",
    "        K.clear_session()\n",
    "        self.generate_model(params)\n",
    "        self.compile_model(self.loss_function, params[self.optimizer])\n",
    "        return\n",
    "    \n",
    "    def test_params(self, hpa):\n",
    "        K.clear_session()\n",
    "        params = {h: hpa[h.name] for h in self.hparams}\n",
    "        self.generate_model(params)\n",
    "        self.compile_model(self.loss_function, params[self.optimizer])\n",
    "        self.run(self.log_dir + \"tune/testhpgrad-1\", params, train_dataset, validation_dataset)\n",
    "        return\n",
    "    \n",
    "    def eval_test(self, test):\n",
    "        _, acc = self.model.evaluate(test)\n",
    "        print(\"Accuracy on test set: \", acc)\n",
    "        return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INIT TIMESTAMP:  1577701799\n"
     ]
    }
   ],
   "source": [
    "m = MultiLayerRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'optimizer': 'adam', 'num_units_l1': 8, 'num_units_l2': 32, 'num_units_l3': 10, 'dropout': 0.3}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 32)                1856      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 526,037\n",
      "Trainable params: 526,037\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shrutiS/workspace/tftest/lib64/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 4s 4s/step - loss: 3.1756 - accuracy: 0.3750WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.227372). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.227372). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 302s 1s/step - loss: nan - accuracy: 0.4932 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 290s 1s/step - loss: nan - accuracy: 0.4993 - val_loss: nan - val_accuracy: 0.5018\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 289s 1s/step - loss: nan - accuracy: 0.5013 - val_loss: nan - val_accuracy: 0.4982\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 284s 1s/step - loss: nan - accuracy: 0.4989 - val_loss: nan - val_accuracy: 0.4982\n",
      "157/157 [==============================] - 29s 184ms/step - loss: nan - accuracy: 0.4982\n",
      "--- Starting trial: run-1\n",
      "{'optimizer': 'adam', 'num_units_l1': 8, 'num_units_l2': 8, 'num_units_l3': 40, 'dropout': 0.4}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 8)                 704       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                360       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 524,945\n",
      "Trainable params: 524,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      1/Unknown - 3s 3s/step - loss: 7.8586 - accuracy: 0.6406WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (2.829424). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (2.829424). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 290s 1s/step - loss: 1.5771 - accuracy: 0.4983 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.9451 - accuracy: 0.5020 - val_loss: 0.8842 - val_accuracy: 0.4982\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 271s 1s/step - loss: 0.8626 - accuracy: 0.5012 - val_loss: 0.8358 - val_accuracy: 0.4982\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.8240 - accuracy: 0.4941 - val_loss: 0.8082 - val_accuracy: 0.5018\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 278s 1s/step - loss: 0.8006 - accuracy: 0.4957 - val_loss: 0.7899 - val_accuracy: 0.5018\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 278s 1s/step - loss: 0.7845 - accuracy: 0.4988 - val_loss: 0.7767 - val_accuracy: 0.4982\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 279s 1s/step - loss: 0.7726 - accuracy: 0.5005 - val_loss: 0.7667 - val_accuracy: 0.5018\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 273s 1s/step - loss: 0.7636 - accuracy: 0.4948 - val_loss: 0.7590 - val_accuracy: 0.4982\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 274s 1s/step - loss: 0.7565 - accuracy: 0.4950 - val_loss: 0.7528 - val_accuracy: 0.4982\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.7509 - accuracy: 0.4983 - val_loss: 0.7480 - val_accuracy: 0.4982\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.7480 - accuracy: 0.4982\n",
      "--- Starting trial: run-2\n",
      "{'optimizer': 'adam', 'num_units_l1': 8, 'num_units_l2': 8, 'num_units_l3': 10, 'dropout': 0.3}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 8)                 704       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 524,645\n",
      "Trainable params: 524,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      1/Unknown - 3s 3s/step - loss: 3.0089 - accuracy: 0.5156WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.193853). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.193853). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 290s 1s/step - loss: 0.8963 - accuracy: 0.5017 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 275s 1s/step - loss: 0.7156 - accuracy: 0.4961 - val_loss: 0.7020 - val_accuracy: 0.5018\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 273s 1s/step - loss: 0.6984 - accuracy: 0.5015 - val_loss: 0.6949 - val_accuracy: 0.4982\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 278s 1s/step - loss: 0.6941 - accuracy: 0.4995 - val_loss: 0.6934 - val_accuracy: 0.4982\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 277s 1s/step - loss: 0.6933 - accuracy: 0.5012 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 279s 1s/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 279s 1s/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 275s 1s/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 271s 1s/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 269s 1s/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.6932 - accuracy: 0.4982\n",
      "--- Starting trial: run-3\n",
      "{'optimizer': 'adam', 'num_units_l1': 16, 'num_units_l2': 64, 'num_units_l3': 10, 'dropout': 0.4}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 64)                6400      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 530,901\n",
      "Trainable params: 530,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      1/Unknown - 4s 4s/step - loss: 11.3519 - accuracy: 0.4375WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.372281). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.372281). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 297s 1s/step - loss: 1.7245 - accuracy: 0.4997 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 285s 1s/step - loss: 1.1867 - accuracy: 0.4984 - val_loss: 1.1291 - val_accuracy: 0.5018\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 287s 1s/step - loss: 1.1096 - accuracy: 0.5007 - val_loss: 1.0861 - val_accuracy: 0.4982\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 284s 1s/step - loss: 1.0761 - accuracy: 0.4950 - val_loss: 1.0628 - val_accuracy: 0.4987\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 291s 1s/step - loss: 1.0563 - accuracy: 0.4975 - val_loss: 1.0469 - val_accuracy: 0.5018\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 294s 1s/step - loss: 1.0418 - accuracy: 0.5012 - val_loss: 1.0342 - val_accuracy: 0.4982\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 293s 1s/step - loss: 1.0297 - accuracy: 0.5012 - val_loss: 1.0229 - val_accuracy: 0.4982\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 290s 1s/step - loss: 1.0187 - accuracy: 0.4969 - val_loss: 1.0122 - val_accuracy: 0.4982\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 292s 1s/step - loss: 1.0082 - accuracy: 0.4991 - val_loss: 1.0017 - val_accuracy: 0.4982\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 292s 1s/step - loss: 0.9977 - accuracy: 0.4992 - val_loss: 0.9913 - val_accuracy: 0.4982\n",
      "157/157 [==============================] - 30s 190ms/step - loss: 0.9913 - accuracy: 0.4982\n",
      "--- Starting trial: run-4\n",
      "{'optimizer': 'sgd', 'num_units_l1': 8, 'num_units_l2': 16, 'num_units_l3': 40, 'dropout': 0.4}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 16)                960       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                680       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 525,521\n",
      "Trainable params: 525,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      1/Unknown - 4s 4s/step - loss: 3.1319 - accuracy: 0.5000WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (2.499222). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (2.499222). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 291s 1s/step - loss: nan - accuracy: 0.4937 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 287s 1s/step - loss: nan - accuracy: 0.4980 - val_loss: nan - val_accuracy: 0.4982\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 282s 1s/step - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.4982\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 279s 1s/step - loss: nan - accuracy: 0.4992 - val_loss: nan - val_accuracy: 0.4982\n",
      "157/157 [==============================] - 28s 178ms/step - loss: nan - accuracy: 0.4982\n",
      "--- Starting trial: run-5\n",
      "{'optimizer': 'sgd', 'num_units_l1': 32, 'num_units_l2': 16, 'num_units_l3': 10, 'dropout': 0.4}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 16)                3840      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 527,861\n",
      "Trainable params: 527,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      1/Unknown - 4s 4s/step - loss: 3.4273 - accuracy: 0.5156WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (2.986428). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (2.986428). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 296s 1s/step - loss: nan - accuracy: 0.4973 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 286s 1s/step - loss: nan - accuracy: 0.4969 - val_loss: nan - val_accuracy: 0.4982\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 286s 1s/step - loss: nan - accuracy: 0.5012 - val_loss: nan - val_accuracy: 0.4982\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 292s 1s/step - loss: nan - accuracy: 0.5008 - val_loss: nan - val_accuracy: 0.4982\n",
      "157/157 [==============================] - 30s 191ms/step - loss: nan - accuracy: 0.4982\n",
      "--- Starting trial: run-6\n",
      "{'optimizer': 'adam', 'num_units_l1': 8, 'num_units_l2': 64, 'num_units_l3': 10, 'dropout': 0.4}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 64)                5184      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 529,685\n",
      "Trainable params: 529,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      1/Unknown - 4s 4s/step - loss: 9.3919 - accuracy: 0.5625WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.380283). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.380283). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 296s 1s/step - loss: 1.9201 - accuracy: 0.5024 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 283s 1s/step - loss: 1.2608 - accuracy: 0.4989 - val_loss: 1.1860 - val_accuracy: 0.4980\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 281s 1s/step - loss: 1.1508 - accuracy: 0.5013 - val_loss: 1.1015 - val_accuracy: 0.4981\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 273s 1s/step - loss: 1.0756 - accuracy: 0.4977 - val_loss: 1.0379 - val_accuracy: 0.4982\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 282s 1s/step - loss: 1.0174 - accuracy: 0.4953 - val_loss: 0.9870 - val_accuracy: 0.4982\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 276s 1s/step - loss: 0.9700 - accuracy: 0.5012 - val_loss: 0.9448 - val_accuracy: 0.4981\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 276s 1s/step - loss: 0.9307 - accuracy: 0.4969 - val_loss: 0.9095 - val_accuracy: 0.4982\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 270s 1s/step - loss: 0.8976 - accuracy: 0.5012 - val_loss: 0.8797 - val_accuracy: 0.4982\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.8696 - accuracy: 0.5004 - val_loss: 0.8545 - val_accuracy: 0.4982\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 279s 1s/step - loss: 0.8460 - accuracy: 0.4948 - val_loss: 0.8333 - val_accuracy: 0.4982\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 0.8333 - accuracy: 0.4982\n",
      "--- Starting trial: run-7\n",
      "{'optimizer': 'sgd', 'num_units_l1': 32, 'num_units_l2': 8, 'num_units_l3': 40, 'dropout': 0.4}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 8)                 3392      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                360       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 527,633\n",
      "Trainable params: 527,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      1/Unknown - 3s 3s/step - loss: 3.1608 - accuracy: 0.5156WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.224398). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.224398). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 291s 1s/step - loss: nan - accuracy: 0.5019 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 282s 1s/step - loss: nan - accuracy: 0.4903 - val_loss: nan - val_accuracy: 0.4982\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 281s 1s/step - loss: nan - accuracy: 0.4963 - val_loss: nan - val_accuracy: 0.4982\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 279s 1s/step - loss: nan - accuracy: 0.4984 - val_loss: nan - val_accuracy: 0.4982\n",
      "157/157 [==============================] - 29s 187ms/step - loss: nan - accuracy: 0.4982\n",
      "--- Starting trial: run-8\n",
      "{'optimizer': 'adam', 'num_units_l1': 64, 'num_units_l2': 8, 'num_units_l3': 40, 'dropout': 0.4}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 8)                 8768      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                360       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 533,009\n",
      "Trainable params: 533,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      1/Unknown - 4s 4s/step - loss: 3.3372 - accuracy: 0.5312WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.899584). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.899584). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 296s 1s/step - loss: nan - accuracy: 0.4987 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 282s 1s/step - loss: nan - accuracy: 0.4996 - val_loss: nan - val_accuracy: 0.5018\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 282s 1s/step - loss: nan - accuracy: 0.4932 - val_loss: nan - val_accuracy: 0.4982\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 282s 1s/step - loss: nan - accuracy: 0.4960 - val_loss: nan - val_accuracy: 0.4982\n",
      "157/157 [==============================] - 29s 186ms/step - loss: nan - accuracy: 0.4982\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "points_explored, acc_params = m.random_search(train_dataset, validation_dataset, 42)\n",
    "randomized_search_time = time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points explored:  9\n",
      "Accuracy for hparameters:  [(0.4982, {HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam', HParam(name='num_units_l1', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 8, HParam(name='num_units_l2', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 32, HParam(name='num_units_l3', domain=Discrete([10, 25, 40]), display_name=None, description=None): 10, HParam(name='dropout', domain=Discrete([0.3, 0.4]), display_name=None, description=None): 0.3}), (0.4982, {HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam', HParam(name='num_units_l1', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 8, HParam(name='num_units_l2', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 8, HParam(name='num_units_l3', domain=Discrete([10, 25, 40]), display_name=None, description=None): 40, HParam(name='dropout', domain=Discrete([0.3, 0.4]), display_name=None, description=None): 0.4}), (0.4982, {HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam', HParam(name='num_units_l1', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 8, HParam(name='num_units_l2', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 8, HParam(name='num_units_l3', domain=Discrete([10, 25, 40]), display_name=None, description=None): 10, HParam(name='dropout', domain=Discrete([0.3, 0.4]), display_name=None, description=None): 0.3}), (0.4982, {HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam', HParam(name='num_units_l1', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 16, HParam(name='num_units_l2', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 64, HParam(name='num_units_l3', domain=Discrete([10, 25, 40]), display_name=None, description=None): 10, HParam(name='dropout', domain=Discrete([0.3, 0.4]), display_name=None, description=None): 0.4}), (0.4982, {HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd', HParam(name='num_units_l1', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 8, HParam(name='num_units_l2', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 16, HParam(name='num_units_l3', domain=Discrete([10, 25, 40]), display_name=None, description=None): 40, HParam(name='dropout', domain=Discrete([0.3, 0.4]), display_name=None, description=None): 0.4}), (0.4982, {HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd', HParam(name='num_units_l1', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 32, HParam(name='num_units_l2', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 16, HParam(name='num_units_l3', domain=Discrete([10, 25, 40]), display_name=None, description=None): 10, HParam(name='dropout', domain=Discrete([0.3, 0.4]), display_name=None, description=None): 0.4}), (0.4982, {HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam', HParam(name='num_units_l1', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 8, HParam(name='num_units_l2', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 64, HParam(name='num_units_l3', domain=Discrete([10, 25, 40]), display_name=None, description=None): 10, HParam(name='dropout', domain=Discrete([0.3, 0.4]), display_name=None, description=None): 0.4}), (0.4982, {HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd', HParam(name='num_units_l1', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 32, HParam(name='num_units_l2', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 8, HParam(name='num_units_l3', domain=Discrete([10, 25, 40]), display_name=None, description=None): 40, HParam(name='dropout', domain=Discrete([0.3, 0.4]), display_name=None, description=None): 0.4}), (0.4982, {HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam', HParam(name='num_units_l1', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 64, HParam(name='num_units_l2', domain=Discrete([8, 16, 32, 64]), display_name=None, description=None): 8, HParam(name='num_units_l3', domain=Discrete([10, 25, 40]), display_name=None, description=None): 40, HParam(name='dropout', domain=Discrete([0.3, 0.4]), display_name=None, description=None): 0.4})]\n"
     ]
    }
   ],
   "source": [
    "print(\"Points explored: \", points_explored)\n",
    "print(\"Accuracy for hparameters: \", acc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = sorted(acc_params, key=lambda x: x[0], reverse=True)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 32)                1856      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 526,037\n",
      "Trainable params: 526,037\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "391/391 [==============================] - 70s 180ms/step - loss: 4.0528 - accuracy: 0.4999\n",
      "Accuracy on test set:  0.49988\n"
     ]
    }
   ],
   "source": [
    "m.setup_model(opt_params)\n",
    "m.eval_test(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17247.224401712418\n"
     ]
    }
   ],
   "source": [
    "print(randomized_search_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-58fd2a2cd2b2f343\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-58fd2a2cd2b2f343\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir ./tf_logs/rnn_classification_1577701799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/rnn_el.png \"Loss plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/rnn_loss_nan.png \"loss nan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/rnn_hparams.png \"hparams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpa = {'optimizer': 'sgd', 'num_units_l1': 8, 'num_units_l2': 16, 'num_units_l3': 40, 'dropout': 0.4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INIT TIMESTAMP:  1577879738\n"
     ]
    }
   ],
   "source": [
    "m1 = MultiLayerRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 16)                960       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                680       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 525,521\n",
      "Trainable params: 525,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 16)                960       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                680       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 525,521\n",
      "Trainable params: 525,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "      1/Unknown - 3s 3s/step - loss: 0.6931 - accuracy: 0.6250WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.022904). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.022904). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    235/Unknown - 267s 1s/step - loss: 0.6932 - accuracy: 0.5012> <ipython-input-44-468192c76b57>(12)on_epoch_end()\n",
      "-> for i in range(0, len(x)):\n",
      "(Pdb) continue\n",
      "235/235 [==============================] - 376s 2s/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "156/157 [============================>.] - ETA: 1s - loss: 0.6932 - accuracy: 0.5011> <ipython-input-44-468192c76b57>(12)on_epoch_end()\n",
      "-> for i in range(0, len(x)):\n",
      "(Pdb) tf.reduce_mean(self.model.trainable_weights[0])\n",
      "<tf.Tensor: id=22043, shape=(), dtype=float32, numpy=nan>\n",
      "(Pdb) continue\n",
      "235/235 [==============================] - 449s 2s/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.4982\n",
      "Epoch 3/3\n",
      "156/157 [============================>.] - ETA: 1s - loss: 0.6932 - accuracy: 0.4980> <ipython-input-44-468192c76b57>(12)on_epoch_end()\n",
      "-> for i in range(0, len(x)):\n",
      "(Pdb) continue\n",
      "235/235 [==============================] - 481s 2s/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.6932 - accuracy: 0.4982\n"
     ]
    }
   ],
   "source": [
    "m1.test_params(hpa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clipping the value of gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_opt = tf.optimizers.SGD(clipvalue=5.0)\n",
    "hpa = {'optimizer': sgd_opt, 'num_units_l1': 8, 'num_units_l2': 16, 'num_units_l3': 40, 'dropout': 0.4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INIT TIMESTAMP:  1577882151\n"
     ]
    }
   ],
   "source": [
    "m2 = MultiLayerRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 16)                960       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                680       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 525,521\n",
      "Trainable params: 525,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          523840    \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 16)                960       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                680       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 525,521\n",
      "Trainable params: 525,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      1/Unknown - 3s 3s/step - loss: 0.6931 - accuracy: 0.4688WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.071765). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.071765). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 297s 1s/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 279s 1s/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 274s 1s/step - loss: 0.6931 - accuracy: 0.5012 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 273s 1s/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 282s 1s/step - loss: 0.6931 - accuracy: 0.5012 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 280s 1s/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 278s 1s/step - loss: 0.6931 - accuracy: 0.5012 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 285s 1s/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 276s 1s/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 0.6932 - accuracy: 0.4982\n"
     ]
    }
   ],
   "source": [
    "m2.test_params(hpa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](rnn_clipgradient.png \"Gradient clipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dark blue lines are the training accuracy and loss, and the light blue is the validation accuracy and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(3, 3)\n",
    "fig.suptitle('Gradients with epochs')\n",
    "\n",
    "for i in range(0, 3):\n",
    "    for j in range(0, 3):\n",
    "        ax[i, j].plot(list(range(1, len(grad_mean[i+j])+1 )), grad_mean[i+j])\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "8.RNN-Text Classification Part II.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tftest",
   "language": "python",
   "name": "tftest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
