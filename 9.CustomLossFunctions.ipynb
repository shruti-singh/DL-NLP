{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SWc0CkHwWX8G"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aEElYFvfWeyE",
    "outputId": "be0086cb-eb74-46af-cc8f-630d92585c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oaNi8GiiWinf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.keras.backend import _constant_to_tensor\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops, clip_ops\n",
    "import pdb\n",
    "import numpy as np\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WO-fVp1Gk8rb"
   },
   "outputs": [],
   "source": [
    "class LossFunction:\n",
    "    \n",
    "    @staticmethod\n",
    "    def mean_squared_error(y_true, y_pred):\n",
    "        '''\n",
    "        loss = mean(square(y_true-y_pred))\n",
    "        '''\n",
    "        return tf.reduce_mean(tf.math.squared_difference(y_true, y_pred))\n",
    "    \n",
    "    @staticmethod\n",
    "    def mean_absolute_error(y_true, y_pred):\n",
    "        '''\n",
    "        loss = abs(y_true-y_pred)\n",
    "        '''\n",
    "        return tf.reduce_mean(tf.math.abs(tf.math.subtract(y_true, y_pred)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def binary_crossentropy(y_true, y_pred, from_logits=False):\n",
    "        def get_epsilon():\n",
    "            # epsilon_value = 1e-7\n",
    "            return tf.keras.backend.epsilon()\n",
    "        \n",
    "        if not from_logits:\n",
    "#             if y_pred.op.type == \"Sigmoid\":\n",
    "#                 TODO: dont clip. Use the from_logits directly.\n",
    "            epsilon = get_epsilon()\n",
    "            clipped_y_pred = tf.clip_by_value(y_pred, clip_value_min=epsilon, clip_value_max=(1.-epsilon))\n",
    "            bce = tf.math.multiply(y_true, tf.math.log(tf.math.add(clipped_y_pred, epsilon)))\n",
    "            temp = tf.math.multiply(tf.math.subtract(1., y_true), tf.math.log(tf.math.add(epsilon, tf.math.subtract(1., clipped_y_pred))))\n",
    "            return tf.math.negative(tf.reduce_mean(tf.math.add(bce, temp)))\n",
    "        else:\n",
    "            # - x * z + log(1 + exp(x)), x = logits, z = labels\n",
    "            return tf.reduce_mean(tf.math.add(tf.math.negative(tf.math.multiply(y_pred, y_true)), tf.math.log(tf.math.add(1., tf.math.exp(y_pred)))))\n",
    "    \n",
    "    @staticmethod\n",
    "    def categorical_crossentropy(y_true, y_pred, from_logits=False):\n",
    "        # Used when there are two or more label classes. Labels are expected to be provided in a one_hot representation. \n",
    "        # If the labels are to be provided as integers, SparseCategoricalCrossentropy loss is used. There should be #classes floating point values per feature.\n",
    "        def get_epsilon():\n",
    "            return tf.keras.backend.epsilon()\n",
    "        if not from_logits:\n",
    "            epsilon = get_epsilon()\n",
    "            clipped_y_pred = tf.clip_by_value(y_pred, clip_value_min=epsilon, clip_value_max=(1.-epsilon))\n",
    "            temp = math_ops.reduce_sum(y_true * math_ops.log(clipped_y_pred), axis=-1)\n",
    "            return tf.math.negative(tf.reduce_mean(K.flatten(temp)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def hinge(y_true, y_pred):\n",
    "        '''\n",
    "        labels are expected to be -1 or 1.\n",
    "        loss = max(1 - y_true * y_pred, 0)\n",
    "        '''\n",
    "        return tf.reduce_mean(tf.math.maximum(tf.subtract(1., tf.math.multiply(y_true, y_pred)), 0.))\n",
    "\n",
    "    @staticmethod\n",
    "    def kl_divergence(y_true, y_pred):\n",
    "        '''\n",
    "        loss = y_true * log(y_true / y_pred)\n",
    "        '''\n",
    "        return tf.reduce_sum(tf.math.multiply(y_true, tf.math.log(tf.math.divide(y_true, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vWXEJEf-IKa"
   },
   "outputs": [],
   "source": [
    "class TestLossFunctions(unittest.TestCase):\n",
    "\n",
    "    def test_mse(self):\n",
    "        y_true = tf.Variable([0., 0., 1., 1.])\n",
    "        y_pred = tf.Variable([1., 1., 1., 0.])\n",
    "        x = tf.keras.backend.placeholder(shape=(None,))\n",
    "        y = tf.keras.backend.placeholder(shape=(None,))\n",
    "\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "        custom_mse = K.function([x,y], [LossFunction.mean_squared_error(x,y)]) \n",
    "        \n",
    "        self.assertEqual(custom_mse([y_true, y_pred]), [mse(y_true, y_pred).numpy()])\n",
    "    \n",
    "    def test_mae(self):\n",
    "        y_true = tf.Variable([0., 0., 1., 1.])\n",
    "        y_pred = tf.Variable([1., 1., 1., 0.])\n",
    "        x = tf.keras.backend.placeholder(shape=(None,))\n",
    "        y = tf.keras.backend.placeholder(shape=(None,))\n",
    "        \n",
    "        mae = tf.keras.losses.MeanAbsoluteError()\n",
    "        custom_mae = K.function([x,y], [LossFunction.mean_absolute_error(x,y)]) \n",
    "        \n",
    "        self.assertEqual(custom_mae([y_true, y_pred]), [mae(y_true, y_pred).numpy()])\n",
    "    \n",
    "    def test_bce(self):\n",
    "        y_true = tf.Variable([0., 0., 1., 1.])\n",
    "        y_pred = tf.Variable([1., 1., 1., 0.])\n",
    "        x = tf.keras.backend.placeholder(shape=(None,))\n",
    "        y = tf.keras.backend.placeholder(shape=(None,))\n",
    "        \n",
    "        bce = tf.keras.losses.BinaryCrossentropy()\n",
    "        custom_bce = K.function([x,y], [LossFunction.binary_crossentropy(x,y)]) \n",
    "        \n",
    "        self.assertEqual(custom_bce([y_true, y_pred]), [bce(y_true, y_pred).numpy()])\n",
    "    \n",
    "    def test_cce(self):\n",
    "        y_true = tf.Variable([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])\n",
    "        y_pred = tf.Variable([[.9, .05, .05], [.05, .89, .06], [.05, .01, .94]])\n",
    "        x = tf.keras.backend.placeholder(shape=(None,))\n",
    "        y = tf.keras.backend.placeholder(shape=(None,))\n",
    "        \n",
    "        cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "        custom_cce = K.function([x,y], [LossFunction.categorical_crossentropy(x,y)]) \n",
    "        \n",
    "        self.assertEqual(custom_cce([y_true, y_pred]), [cce(y_true, y_pred).numpy()])\n",
    "    \n",
    "    def test_hinge(self):\n",
    "        y_true = tf.Variable([-1., -1., 1., 1.])\n",
    "        y_pred = tf.Variable([1., 1., 1., -1.])\n",
    "        x = tf.keras.backend.placeholder(shape=(None,))\n",
    "        y = tf.keras.backend.placeholder(shape=(None,))\n",
    "        \n",
    "        hinge = tf.keras.losses.Hinge()\n",
    "        custom_hinge = K.function([x,y], [LossFunction.hinge(x,y)]) \n",
    "        \n",
    "        self.assertEqual(custom_hinge([y_true, y_pred]), [hinge(y_true, y_pred).numpy()])\n",
    "    \n",
    "    def test_kld(self):\n",
    "        y_true = tf.Variable([.4, .9, .2])\n",
    "        y_pred = tf.Variable([.5, .8, .12])\n",
    "        x = tf.keras.backend.placeholder(shape=(None,))\n",
    "        y = tf.keras.backend.placeholder(shape=(None,))\n",
    "        \n",
    "        kld = tf.keras.losses.KLDivergence()\n",
    "        custom_kld = K.function([x,y], [LossFunction.kl_divergence(x,y)]) \n",
    "        \n",
    "        self.assertEqual(custom_kld([y_true, y_pred]), [kld(y_true, y_pred).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "E40J8qQq_NWy",
    "outputId": "1060a79a-560b-4cbf-a611-0f02b8fcd59c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_bce (__main__.TestLossFunctions) ... ok\n",
      "test_cce (__main__.TestLossFunctions) ... ok\n",
      "test_hinge (__main__.TestLossFunctions) ... ok\n",
      "test_kld (__main__.TestLossFunctions) ... ok\n",
      "test_mae (__main__.TestLossFunctions) ... ok\n",
      "test_mse (__main__.TestLossFunctions) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.205s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fcbf02e7860>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "9.CustomLossFunctions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
