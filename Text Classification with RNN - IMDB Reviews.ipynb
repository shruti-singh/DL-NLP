{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.disable_progress_bar()\n",
    "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*tfds* includes a set of *TextEncoders* and *Tokenizers*.\n",
    "\n",
    "[**TextEncoder**](https://www.tensorflow.org/datasets/api_docs/python/tfds/features/text/TextEncoder) class in TensorFlow: Is an abstract base class for conversion between integers and text. Since text data has variable length and requires padding, ID 0 is always reserved for padding.\n",
    "\n",
    "It has *vocab_size* as an attribute. vocab_size includes ID 0.\n",
    "\n",
    "Method *encode()* encodes text into a list of integers. It never returns ID 0, and all IDs are always 1+.\n",
    "Method *decode()* decodes a list of integers into text. It drops 0 in the input IDs.\n",
    "\n",
    "\n",
    "[**SubwordTextEncoder**](https://www.tensorflow.org/datasets/api_docs/python/tfds/features/text/SubwordTextEncoder) is an invertible TextEncoder using word pieces with a byte-level fallback. This encoding is fully invertible as all out-of-vocab wordpieces are byte-encoded. \n",
    "\n",
    "It contains *vocab_list* attribute which contains a list of subwords for the vocabulary. An underscore at the end of the vocabulary indicates the end of the word. Underscores in the interior of subword are disallowed and should be used with escape sequence.\n",
    "\n",
    "**The dataset *info* includes the SubTextEncoder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info features:  FeaturesDict({'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>), 'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2)})\n",
      "\n",
      " Vocabulary size:  8185\n",
      "\n",
      " Sample Subwords ['in_', 'I_', 'that_', 'this_', 'it_', ' /><', ' />', 'was_', 'The_', 'as_']\n"
     ]
    }
   ],
   "source": [
    "print(\"info features: \", info.features)\n",
    "encoder = info.features[\"text\"].encoder\n",
    "print(\"\\n Vocabulary size: \", encoder.vocab_size)\n",
    "print(\"\\n Sample Subwords\", encoder.subwords[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed above, the encoding is invertible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string:  IMDB Review Classification\n",
      "Encoded string is:  [5469, 7997, 2432, 3621, 739, 656, 2369, 1395, 3203, 757]\n",
      "Decoded string si:  IMDB Review Classification\n",
      "5469 ----> IM\n",
      "7997 ----> D\n",
      "2432 ----> B \n",
      "3621 ----> Rev\n",
      "739 ----> ie\n",
      "656 ----> w \n",
      "2369 ----> Cla\n",
      "1395 ----> ssi\n",
      "3203 ----> fic\n",
      "757 ----> ation\n"
     ]
    }
   ],
   "source": [
    "sample_str = \"IMDB Review Classification\"\n",
    "print(\"Original string: \", sample_str)\n",
    "\n",
    "encoded_str = encoder.encode(sample_str)\n",
    "print(\"Encoded string is: \", encoded_str)\n",
    "\n",
    "decoded_str = encoder.decode(encoded_str)\n",
    "print(\"Decoded string si: \", decoded_str)\n",
    "\n",
    "for index in encoded_str:\n",
    "    print(\"%s ----> %s\"%(index, encoder.decode([index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create batches of the encoded strings. **padded_batch** is used to zero pad the sequences to the length of the longest sequence in the batch. It combines consecutive elements of the dataset into padded batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_shapes returns the shape of each component of an element of this dataset.\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)\n",
    "\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE, test_dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-221290a02f41>:2: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-221290a02f41>:2: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "inputs must be a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-221290a02f41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbasic_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasicRNNCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/research/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mstatic_rnn\u001b[0;34m(cell, inputs, initial_state, dtype, sequence_length, scope)\u001b[0m\n\u001b[1;32m   1277\u001b[0m   \u001b[0mrnn_cell_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_like_rnncell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cell\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inputs must be a sequence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inputs must not be empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: inputs must be a sequence"
     ]
    }
   ],
   "source": [
    "n_hidden = 5\n",
    "basic_cell = rnn.BasicRNNCell(n_hidden)\n",
    "# output_seqs, states = rnn.static_rnn(basic_cell, train_dataset, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# TODO: Read about layers: tf.keras.layers.RNN, tf.keras.layers.LSTM, tf.keras.layers.GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/SingleRNN.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
